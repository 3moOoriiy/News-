import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd
from datetime import datetime
import io

# -------- Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… requests Ùˆ BeautifulSoup --------
def fetch_news(url, keywords):
    try:
        response = requests.get(url)
        response.raise_for_status()
    except Exception as e:
        st.error(f"âŒ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙØ­Ø©: {e}")
        return []

    soup = BeautifulSoup(response.content, "html.parser")

    news_list = []

    # Ù†Ø­Ø§ÙˆÙ„ Ù†Ù„Ø§Ù‚ÙŠ Ù‚Ø³Ù… "Ø¢Ø®Ø± Ø§Ù„Ø£Ø®Ø¨Ø§Ø±"
    section = soup.find('section', class_='latest-news')  # Ù†Ø­Ø§ÙˆÙ„ Ù†Ù„Ø§Ù‚ÙŠ Ø£Ù‚Ø±Ø¨ Section Ù„Ùˆ Ù…ÙˆØ¬ÙˆØ¯
    if not section:
        st.warning("âš ï¸ Ù…Ø´ Ù„Ø§Ù‚ÙŠ Ù‚Ø³Ù… 'Ø¢Ø®Ø± Ø§Ù„Ø£Ø®Ø¨Ø§Ø±' Ø¨Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø¹Ø§Ø¯ÙŠØ©ØŒ Ø¨Ø­Ø§ÙˆÙ„ Ø£Ø¬ÙŠØ¨ Ø£ÙˆÙ„ Ø§Ù„ÙƒØ±ÙˆØª.")
        cards = soup.select('div.comp_1_item')
    else:
        cards = section.select('div.comp_1_item')

    cards = cards[:10]  # Ø£ÙˆÙ„ 10 Ø£Ø®Ø¨Ø§Ø± ÙÙ‚Ø·

    for card in cards:
        title_el = card.find('h3', class_='comp_1_item_header')
        link_el = card.find('a')

        if title_el and link_el:
            title = title_el.get_text(strip=True)
            link = link_el.get('href')
            if not link.startswith("http"):
                link = "https://www.skynewsarabia.com" + link  # Ù„Ùˆ Ø§Ù„Ø±Ø§Ø¨Ø· Ù†Ø³Ø¨ÙŠ

            if keywords:
                if any(keyword.lower() in title.lower() for keyword in keywords):
                    news_list.append({
                        "ØªØ§Ø±ÙŠØ®": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                        "Ø§Ù„Ø¹Ù†ÙˆØ§Ù†": title,
                        "Ø§Ù„Ø±Ø§Ø¨Ø·": link
                    })
            else:
                news_list.append({
                    "ØªØ§Ø±ÙŠØ®": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "Ø§Ù„Ø¹Ù†ÙˆØ§Ù†": title,
                    "Ø§Ù„Ø±Ø§Ø¨Ø·": link
                })

    return news_list

# -------- Streamlit App --------
st.set_page_config(page_title="Ø³ÙƒØ§ÙŠ Ù†ÙŠÙˆØ² - Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¢Ø®Ø± Ø§Ù„Ø£Ø®Ø¨Ø§Ø±", layout="centered")

st.title("ğŸ“° Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¢Ø®Ø± Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù…Ù† Sky News Arabia (Ø¨Ø¯ÙˆÙ† Selenium)")

# Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ø±Ø§Ø¨Ø·
url = st.text_input("Ø§Ø¯Ø®Ù„ Ø±Ø§Ø¨Ø· ØµÙØ­Ø© Ø§Ù„Ø£Ø®Ø¨Ø§Ø±:", value="https://www.skynewsarabia.com/")

# Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
keywords_input = st.text_input("Ø§Ø¯Ø®Ù„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© (Ù…ÙØµÙˆÙ„Ø© Ø¨ÙÙˆØ§ØµÙ„):", value="")
keywords = [kw.strip() for kw in keywords_input.split(",")] if keywords_input else []

# Ø²Ø±Ø§Ø± Ø§Ù„Ø¨Ø­Ø«
if st.button("ğŸ” Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±"):
    with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±..."):
        news = fetch_news(url, keywords)
        if news:
            df = pd.DataFrame(news)
            st.success(f"âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ {len(df)} Ø®Ø¨Ø±.")

            st.dataframe(df)

            # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                df.to_excel(writer, index=False)
            st.download_button(
                label="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± ÙƒÙ…Ù„Ù Excel",
                data=output.getvalue(),
                file_name="Ø¢Ø®Ø±_Ø§Ù„Ø£Ø®Ø¨Ø§Ø±_skynews.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
        else:
            st.warning("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£Ø®Ø¨Ø§Ø± ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ø´Ø±ÙˆØ·.")
