import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd
from datetime import datetime
import io

# -------- Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù…Ù† Ø£ÙŠ ÙƒØ±ÙˆØª --------
def fetch_news(url, keywords):
    try:
        response = requests.get(url)
        response.raise_for_status()
    except Exception as e:
        st.error(f"âŒ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙØ­Ø©: {e}")
        return []

    soup = BeautifulSoup(response.content, "html.parser")

    news_list = []

    # Ù†Ø¯ÙˆØ± Ø¹Ù„Ù‰ ÙƒÙ„ Ø§Ù„ÙƒØ±ÙˆØª Ø§Ù„Ù„ÙŠ ÙÙŠÙ‡Ø§ Ø¹Ù†Ø§ÙˆÙŠÙ†
    cards = soup.find_all('a', class_='tile__title')  # Ø§Ù„Ø¹Ù†Ø§ÙˆÙŠÙ† Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ÙÙŠ Ø§Ù„ØµÙØ­Ø©

    if not cards:
        st.warning("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£Ø®Ø¨Ø§Ø± Ø¨Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©.")
        return []

    for card in cards[:20]:  # Ù†Ø¬ÙŠØ¨ Ø£ÙˆÙ„ 20 Ø®Ø¨Ø± Ù…Ø«Ù„Ø§Ù‹
        title = card.get_text(strip=True)
        link = card.get('href')
        if not link.startswith("http"):
            link = "https://www.skynewsarabia.com" + link

        if keywords:
            if any(keyword.lower() in title.lower() for keyword in keywords):
                news_list.append({
                    "ØªØ§Ø±ÙŠØ®": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "Ø§Ù„Ø¹Ù†ÙˆØ§Ù†": title,
                    "Ø§Ù„Ø±Ø§Ø¨Ø·": link
                })
        else:
            news_list.append({
                "ØªØ§Ø±ÙŠØ®": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "Ø§Ù„Ø¹Ù†ÙˆØ§Ù†": title,
                "Ø§Ù„Ø±Ø§Ø¨Ø·": link
            })

    return news_list

# -------- Streamlit App --------
st.set_page_config(page_title="Ø³ÙƒØ§ÙŠ Ù†ÙŠÙˆØ² - Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¢Ø®Ø± Ø§Ù„Ø£Ø®Ø¨Ø§Ø± (Ù…Ø·ÙˆØ±)", layout="centered")

st.title("ğŸ“° Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¢Ø®Ø± Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù…Ù† Sky News Arabia (Ø¨Ø¯ÙˆÙ† Selenium)")

# Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ø±Ø§Ø¨Ø·
url = st.text_input("Ø§Ø¯Ø®Ù„ Ø±Ø§Ø¨Ø· ØµÙØ­Ø© Ø§Ù„Ø£Ø®Ø¨Ø§Ø±:", value="https://www.skynewsarabia.com/")

# Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
keywords_input = st.text_input("Ø§Ø¯Ø®Ù„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© (Ù…ÙØµÙˆÙ„Ø© Ø¨ÙÙˆØ§ØµÙ„):", value="")
keywords = [kw.strip() for kw in keywords_input.split(",")] if keywords_input else []

# Ø²Ø±Ø§Ø± Ø§Ù„Ø¨Ø­Ø«
if st.button("ğŸ” Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±"):
    with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±..."):
        news = fetch_news(url, keywords)
        if news:
            df = pd.DataFrame(news)
            st.success(f"âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ {len(df)} Ø®Ø¨Ø±.")

            st.dataframe(df)

            # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù
            output = io.BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                df.to_excel(writer, index=False)
            st.download_button(
                label="ğŸ“¥ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± ÙƒÙ…Ù„Ù Excel",
                data=output.getvalue(),
                file_name="Ø¢Ø®Ø±_Ø§Ù„Ø£Ø®Ø¨Ø§Ø±_skynews.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
        else:
            st.warning("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£Ø®Ø¨Ø§Ø± ØªØ·Ø§Ø¨Ù‚ Ø§Ù„Ø´Ø±ÙˆØ·.")
