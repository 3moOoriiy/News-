import streamlit as st
import feedparser
from datetime import datetime
from io import BytesIO
import time

from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
from reportlab.lib.pagesizes import A4
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.enums import TA_RIGHT


# -------- ØªÙ„Ø®ÙŠØµ Ø¨Ø³ÙŠØ· --------
def summarize(text, max_words=25):
    return " ".join(text.split()[:max_words]) + "..."


# -------- Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± --------
def fetch_news_with_images(rss_url, keywords):
    feed = feedparser.parse(rss_url)
    news_list = []

    for entry in feed.entries:
        title = entry.title
        summary = entry.get("summary", "")
        link = entry.link
        published = entry.get("published", None)
        try:
            published_dt = datetime.strptime(published, "%a, %d %b %Y %H:%M:%S %Z")
        except:
            published_dt = datetime.now()

        image = ""
        if 'media_content' in entry:
            image = entry.media_content[0].get('url', '')
        elif 'media_thumbnail' in entry:
            image = entry.media_thumbnail[0].get('url', '')

        if keywords:
            if any(keyword.lower() in (title + " " + summary).lower() for keyword in keywords):
                news_list.append({
                    "title": title,
                    "summary": summary,
                    "link": link,
                    "published": published_dt,
                    "image": image
                })
        else:
            news_list.append({
                "title": title,
                "summary": summary,
                "link": link,
                "published": published_dt,
                "image": image
            })

    return news_list


# -------- Ø¥Ù†Ø´Ø§Ø¡ PDF Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… reportlab --------
def export_news_to_pdf(news_list):
    buffer = BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=A4, rightMargin=40, leftMargin=40, topMargin=40, bottomMargin=20)
    styles = getSampleStyleSheet()

    arabic_style = ParagraphStyle(
        name='Arabic',
        parent=styles['Normal'],
        fontName='Helvetica',
        fontSize=12,
        alignment=TA_RIGHT
    )

    story = []

    for item in news_list:
        story.append(Paragraph(f"<b>ğŸ“° Ø§Ù„Ø¹Ù†ÙˆØ§Ù†:</b> {item['title']}", arabic_style))
        story.append(Paragraph(f"<b>ğŸ“… Ø§Ù„ØªØ§Ø±ÙŠØ®:</b> {item['published'].strftime('%Y-%m-%d %H:%M:%S')}", arabic_style))
        story.append(Paragraph(f"<b>ğŸ“„ Ø§Ù„ØªÙ„Ø®ÙŠØµ:</b> {summarize(item['summary'])}", arabic_style))
        story.append(Paragraph(f"<b>ğŸŒ Ø§Ù„Ø±Ø§Ø¨Ø·:</b> {item['link']}", arabic_style))
        story.append(Spacer(1, 14))

    doc.build(story)
    buffer.seek(0)
    return buffer


# -------- ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ --------
st.set_page_config(page_title="Ø£Ø¯Ø§Ø© Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø´Ø§Ù…Ù„Ø©", layout="wide")
st.title("ğŸ“° Ø£Ø¯Ø§Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± - ØªÙ„Ø®ÙŠØµ + ØªØ±ØªÙŠØ¨ + PDF")

rss_feeds = {
    "BBC Ø¹Ø±Ø¨ÙŠ": "http://feeds.bbci.co.uk/arabic/rss.xml",
    "CNN Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©": "http://arabic.cnn.com/rss/latest",
    "RT Arabic": "https://arabic.rt.com/rss/",
    "France24 Ø¹Ø±Ø¨ÙŠ": "https://www.france24.com/ar/rss",
    "Ø§Ù„Ø´Ø±Ù‚ Ø§Ù„Ø£ÙˆØ³Ø·": "https://aawsat.com/home/rss.xml"
}

col1, col2 = st.columns([1, 2])

with col1:
    selected_feed = st.selectbox("ğŸŒ Ø§Ø®ØªØ± Ø§Ù„Ù…ØµØ¯Ø±:", list(rss_feeds.keys()))
    custom_rss = st.text_input("ğŸ”— Ø±Ø§Ø¨Ø· RSS Ù…Ø®ØµØµ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ):", value="")
    keywords_input = st.text_input("ğŸ” ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ©:", value="")
    keywords = [kw.strip() for kw in keywords_input.split(",")] if keywords_input else []
    sort_order = st.radio("ğŸ”ƒ ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±:", ["Ø§Ù„Ø£Ø­Ø¯Ø« Ø£ÙˆÙ„Ù‹Ø§", "Ø§Ù„Ø£Ù‚Ø¯Ù… Ø£ÙˆÙ„Ù‹Ø§"])
    auto_refresh = st.checkbox("â™»ï¸ ØªØ­Ø¯ÙŠØ« ØªÙ„Ù‚Ø§Ø¦ÙŠ ÙƒÙ„ 60 Ø«Ø§Ù†ÙŠØ©")
    run = st.button("ğŸ“¥ Ø¹Ø±Ø¶ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±")

if auto_refresh:
    time.sleep(60)
    st.experimental_rerun()

with col2:
    if run:
        rss_url = custom_rss if custom_rss else rss_feeds[selected_feed]
        news = fetch_news_with_images(rss_url, keywords)

        if not news:
            st.warning("âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø®Ø¨Ø§Ø±.")
        else:
            reverse = True if sort_order == "Ø§Ù„Ø£Ø­Ø¯Ø« Ø£ÙˆÙ„Ù‹Ø§" else False
            news = sorted(news, key=lambda x: x["published"], reverse=reverse)

            st.success(f"âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(news)} Ø®Ø¨Ø±.")
            for item in news:
                with st.container():
                    st.markdown("----")
                    cols = st.columns([1, 3])

                    with cols[0]:
                        if item["image"]:
                            st.image(item["image"], width=140)

                    with cols[1]:
                        st.markdown(f"### ğŸ“° {item['title']}")
                        st.markdown(f"ğŸ“… **Ø§Ù„ØªØ§Ø±ÙŠØ®:** {item['published'].strftime('%Y-%m-%d %H:%M:%S')}")
                        st.markdown(f"**ğŸ“„ Ø§Ù„ØªÙ„Ø®ÙŠØµ:** {summarize(item['summary'])}")
                        st.markdown(f"[ğŸŒ Ø§Ù‚Ø±Ø£ Ø§Ù„Ù…Ø²ÙŠØ¯ â†—]({item['link']})")

            pdf = export_news_to_pdf(news)
            st.download_button("ğŸ“„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± ÙƒÙ€ PDF", data=pdf, file_name="news_report.pdf", mime="application/pdf")
