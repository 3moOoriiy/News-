import streamlit as st
import feedparser
from datetime import datetime
from io import BytesIO
import time

from docx import Document

# -------- ØªÙ„Ø®ÙŠØµ Ø¨Ø³ÙŠØ· --------
def summarize(text, max_words=25):
    return " ".join(text.split()[:max_words]) + "..."

# -------- Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± --------
def fetch_news_with_images(rss_url, keywords):
    feed = feedparser.parse(rss_url)
    news_list = []

    for entry in feed.entries:
        title = entry.title
        summary = entry.get("summary", "")
        link = entry.link
        published = entry.get("published", None)
        try:
            published_dt = datetime.strptime(published, "%a, %d %b %Y %H:%M:%S %Z")
        except:
            published_dt = datetime.now()

        image = ""
        if 'media_content' in entry:
            image = entry.media_content[0].get('url', '')
        elif 'media_thumbnail' in entry:
            image = entry.media_thumbnail[0].get('url', '')

        if keywords:
            if any(keyword.lower() in (title + " " + summary).lower() for keyword in keywords):
                news_list.append({
                    "title": title,
                    "summary": summary,
                    "link": link,
                    "published": published_dt,
                    "image": image
                })
        else:
            news_list.append({
                "title": title,
                "summary": summary,
                "link": link,
                "published": published_dt,
                "image": image
            })

    return news_list

# -------- Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Word --------
def export_news_to_word(news_list):
    doc = Document()

    for item in news_list:
        doc.add_heading(item['title'], level=2)
        doc.add_paragraph(f"ğŸ“… Ø§Ù„ØªØ§Ø±ÙŠØ®: {item['published'].strftime('%Y-%m-%d %H:%M:%S')}")
        doc.add_paragraph(f"ğŸ“„ Ø§Ù„ØªÙ„Ø®ÙŠØµ: {summarize(item['summary'])}")
        doc.add_paragraph(f"ğŸŒ Ø§Ù„Ø±Ø§Ø¨Ø·: {item['link']}")
        doc.add_paragraph('---')

    buffer = BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer

# -------- ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ --------
st.set_page_config(page_title="Ø£Ø¯Ø§Ø© Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ø§Ù„Ø´Ø§Ù…Ù„Ø© - Word", layout="wide")
st.title("ğŸ“° Ø£Ø¯Ø§Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆØ¹Ø±Ø¶ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± ÙˆØªØ­Ù…ÙŠÙ„Ù‡Ø§ ÙƒÙ€ Word")

rss_feeds = {
    "BBC Ø¹Ø±Ø¨ÙŠ": "http://feeds.bbci.co.uk/arabic/rss.xml",
    "CNN Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©": "http://arabic.cnn.com/rss/latest",
    "RT Arabic": "https://arabic.rt.com/rss/",
    "France24 Ø¹Ø±Ø¨ÙŠ": "https://www.france24.com/ar/rss",
    "Ø§Ù„Ø´Ø±Ù‚ Ø§Ù„Ø£ÙˆØ³Ø·": "https://aawsat.com/home/rss.xml"
}

col1, col2 = st.columns([1, 2])

with col1:
    selected_feed = st.selectbox("ğŸŒ Ø§Ø®ØªØ± Ø§Ù„Ù…ØµØ¯Ø±:", list(rss_feeds.keys()))
    custom_rss = st.text_input("ğŸ”— Ø±Ø§Ø¨Ø· RSS Ù…Ø®ØµØµ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ):", value="")
    keywords_input = st.text_input("ğŸ” ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ©:", value="")
    keywords = [kw.strip() for kw in keywords_input.split(",")] if keywords_input else []
    sort_order = st.radio("ğŸ”ƒ ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±:", ["Ø§Ù„Ø£Ø­Ø¯Ø« Ø£ÙˆÙ„Ù‹Ø§", "Ø§Ù„Ø£Ù‚Ø¯Ù… Ø£ÙˆÙ„Ù‹Ø§"])
    auto_refresh = st.checkbox("â™»ï¸ ØªØ­Ø¯ÙŠØ« ØªÙ„Ù‚Ø§Ø¦ÙŠ ÙƒÙ„ 60 Ø«Ø§Ù†ÙŠØ©")
    run = st.button("ğŸ“¥ Ø¹Ø±Ø¶ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±")

if auto_refresh:
    time.sleep(60)
    st.experimental_rerun()

with col2:
    if run:
        rss_url = custom_rss if custom_rss else rss_feeds[selected_feed]
        news = fetch_news_with_images(rss_url, keywords)

        if not news:
            st.warning("âš ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø£Ø®Ø¨Ø§Ø±.")
        else:
            reverse = True if sort_order == "Ø§Ù„Ø£Ø­Ø¯Ø« Ø£ÙˆÙ„Ù‹Ø§" else False
            news = sorted(news, key=lambda x: x["published"], reverse=reverse)

            st.success(f"âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(news)} Ø®Ø¨Ø±.")
            for item in news:
                with st.container():
                    st.markdown("----")
                    cols = st.columns([1, 3])

                    with cols[0]:
                        if item["image"]:
                            st.image(item["image"], width=140)

                    with cols[1]:
                        st.markdown(f"### ğŸ“° {item['title']}")
                        st.markdown(f"ğŸ“… **Ø§Ù„ØªØ§Ø±ÙŠØ®:** {item['published'].strftime('%Y-%m-%d %H:%M:%S')}")
                        st.markdown(f"**ğŸ“„ Ø§Ù„ØªÙ„Ø®ÙŠØµ:** {summarize(item['summary'])}")
                        st.markdown(f"[ğŸŒ Ø§Ù‚Ø±Ø£ Ø§Ù„Ù…Ø²ÙŠØ¯ â†—]({item['link']})")

            word_file = export_news_to_word(news)
            st.download_button("ğŸ“ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± ÙƒÙ€ Word", data=word_file, file_name="news_report.docx", mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document")
