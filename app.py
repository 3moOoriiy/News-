import streamlit as st
import feedparser
from datetime import datetime

# -------- Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± Ù…Ù† RSS --------
def fetch_news_from_rss(rss_url, keywords):
    feed = feedparser.parse(rss_url)
    news_list = []
    total_entries = len(feed.entries)

    for entry in feed.entries:
        title = entry.title
        summary = entry.get("summary", "")
        link = entry.link
        published = entry.get("published", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))

        if keywords:
            if any(keyword.lower() in (title + " " + summary).lower() for keyword in keywords):
                news_list.append({
                    "title": title,
                    "summary": summary,
                    "link": link,
                    "published": published
                })
        else:
            news_list.append({
                "title": title,
                "summary": summary,
                "link": link,
                "published": published
            })

    return news_list, total_entries

# -------- Streamlit App --------
st.set_page_config(page_title="Ø£Ø¯Ø§Ø© Ø§Ù„Ø£Ø®Ø¨Ø§Ø± - Ø¹Ø±Ø¶ ÙƒØ¨Ø·Ø§Ù‚Ø§Øª", layout="wide")
st.title("ğŸ—ï¸ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± ÙˆØ¹Ø±Ø¶Ù‡Ø§ ÙƒØ¨Ø·Ø§Ù‚Ø§Øª (RSS News Cards)")

# Ù‚Ø§Ø¦Ù…Ø© Ù…ØµØ§Ø¯Ø± RSS
rss_feeds = {
    "BBC Ø¹Ø±Ø¨ÙŠ": "http://feeds.bbci.co.uk/arabic/rss.xml",
    "CNN Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©": "http://arabic.cnn.com/rss/latest",
    "RT Arabic": "https://arabic.rt.com/rss/",
    "France24 Ø¹Ø±Ø¨ÙŠ": "https://www.france24.com/ar/rss",
    "Ø§Ù„Ø´Ø±Ù‚ Ø§Ù„Ø£ÙˆØ³Ø·": "https://aawsat.com/home/rss.xml"
}

# ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
col1, col2 = st.columns([1, 2])

with col1:
    selected_feed = st.selectbox("ğŸŒ Ø§Ø®ØªØ± Ù…ØµØ¯Ø± Ø§Ù„Ø£Ø®Ø¨Ø§Ø±:", list(rss_feeds.keys()))
    custom_rss = st.text_input("ğŸ”— Ø£Ø¯Ø®Ù„ Ø±Ø§Ø¨Ø· RSS Ù…Ø®ØµØµ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ):", value="")
    keywords_input = st.text_input("ğŸ” ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© (Ù…ÙØµÙˆÙ„Ø© Ø¨ÙÙˆØ§ØµÙ„):", value="")
    keywords = [kw.strip() for kw in keywords_input.split(",")] if keywords_input else []
    run_scrape = st.button("ğŸ“¥ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±")

with col2:
    if run_scrape:
        with st.spinner("â³ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø±..."):
            rss_url = custom_rss if custom_rss else rss_feeds[selected_feed]
            news, total = fetch_news_from_rss(rss_url, keywords)

            if total == 0:
                st.error("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£Ø®Ø¨Ø§Ø± ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…ØµØ¯Ø±.")
            elif not news:
                st.warning(f"âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø£Ø®Ø¨Ø§Ø± ØªØ·Ø§Ø¨Ù‚ Ø§Ù„ÙƒÙ„Ù…Ø§Øª. ({total} Ø®Ø¨Ø± Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø¯ÙˆÙ† ØªØ·Ø§Ø¨Ù‚).")
            else:
                st.success(f"âœ… ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(news)} Ø®Ø¨Ø± ÙŠØ·Ø§Ø¨Ù‚ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ù…Ù† Ø£ØµÙ„ {total} Ø®Ø¨Ø±.")
                for item in news:
                    with st.container():
                        st.markdown(f"### ğŸ“° {item['title']}")
                        st.markdown(f"**ğŸ•“ Ø§Ù„ØªØ§Ø±ÙŠØ®:** {item['published']}")
                        st.markdown(f"**ğŸ“„ Ø§Ù„ÙˆØµÙ:** {item['summary']}")
                        st.markdown(f"[ğŸŒ Ø§Ù‚Ø±Ø£ Ø§Ù„Ù…Ø²ÙŠØ¯ â†—]({item['link']})")
                        st.markdown("---")
